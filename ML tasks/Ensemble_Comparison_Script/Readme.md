# Ensemble Model Comparison - Iris Dataset
This project compares the performance of three machine learning models — **Logistic Regression**, **Random Forest**, and **XGBoost** — using the classic **Iris dataset**.

The models are evaluated based on their **Accuracy**, **Precision**, **Recall**, and **F1-Score** metrics, and the comparison results are saved into `results.csv`.

---

##  Files Included
- `ensemble_comparison.ipynb` — Main Jupyter Notebook for training and evaluation  
- `IRIS.csv` — Dataset used for model comparison  
- `results.csv` — Output CSV containing model performance metrics  
- `requirements.txt` — Python dependencies required to run the notebook  

---
## Run the notebook:
- Open ensemble_comparison.ipynb in Jupyter Notebook or VS Code.
- Execute all cells sequentially

## Metrics Calculated
Each model is evaluated using:
- Accuracy — How often the model predicts correctly
- Precision — Quality of positive predictions
- Recall — How many actual positives were captured
- F1-Score — Balance between precision and recall

## View Results
After execution, a file named **results.csv** will be generated in the same directory containing performance metrics.